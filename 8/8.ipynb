{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PttAe7Nu5NMv",
        "outputId": "b5e135a6-cb72-4412-ca63-dcb05b118c6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of characters:  5058009\n",
            "the project gutenberg ebook of the complete works of william shakespea\n",
            "chars: the project gutenber\n",
            "indices: [12, 22, 0, 10, 17, 14, 21, 5, 0, 13, 12, 10, 16, 6, 12, 0, 26, 7, 0, 14]\n"
          ]
        }
      ],
      "source": [
        "import urllib3\n",
        "import collections\n",
        "import re\n",
        "shakespeare = 'http://www.gutenberg.org/files/100/100-0.txt'\n",
        "http = urllib3.PoolManager()\n",
        "text = http.request('GET', shakespeare).data.decode('utf-8')\n",
        "raw_dataset = ' '.join(re.sub('[^A-Za-z]+', ' ', text).lower().split())\n",
        "print('number of characters: ', len(raw_dataset))\n",
        "print(raw_dataset[0:70])\n",
        "\n",
        "idx_to_char = list(set(raw_dataset))\n",
        "char_to_idx = dict([(char, i) for i, char in enumerate(idx_to_char)])\n",
        "vocab_size = len(char_to_idx)\n",
        "corpus_indices = [char_to_idx[char] for char in raw_dataset]\n",
        "sample = corpus_indices[:20]\n",
        "print('chars:', ''.join([idx_to_char[idx] for idx in sample]))\n",
        "print('indices:', sample)\n",
        "train_indices = corpus_indices[:-100000]\n",
        "test_indices = corpus_indices[-100000:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcS9Nkfe-rok",
        "outputId": "eee4550f-fe49-4273-bd7a-343c783e9c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['e', 'f', 'x', 'd', 'k', 'j', 'u', 'b', 'y', 'q', ' ', 's', 't', 'c', 'r', 'v', 'g', 'p', 'w', 'a', 'i', 'o', 'h', 'l', 'z', 'm', 'n']\n"
          ]
        }
      ],
      "source": [
        "print(idx_to_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPNvrruy5xp8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRtj8KETXELZ"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.hidden_size = 256\n",
        "        self.rnn = nn.RNN(vocab_size, self.hidden_size)\n",
        "        self.linear = nn.Linear(self.hidden_size, self.vocab_size)\n",
        "\n",
        "    def forward(self, inputs, state):\n",
        "\n",
        "        X = F.one_hot(torch.transpose(inputs,0,1), self.vocab_size)\n",
        "        Y, state = self.rnn(X,state)\n",
        "        output = self.linear(Y.reshape((-1, Y.shape[-1])))\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukIMKq8v5egJ"
      },
      "outputs": [],
      "source": [
        "def initialize_model(m):\n",
        "  if isinstance(m, nn.RNN):\n",
        "        nn.init.xavier_uniform_(m.weight_ih_l0.data)\n",
        "        nn.init.xavier_uniform_(m.weight_hh_l0.data)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias_ih_l0.data, 0)\n",
        "            nn.init.constant_(m.bias_hh_l0.data, 0)\n",
        "  if isinstance(m, nn.Linear):\n",
        "        nn.init.xavier_uniform_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias.data, 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-WaziWzXv_x"
      },
      "outputs": [],
      "source": [
        "def predict_rnn(prefix, num_chars, model, device, vocab_size, idx_to_char, char_to_idx):\n",
        "  output = [char_to_idx[prefix[0]]]\n",
        "  for t in range(num_chars + len(prefix) -1):\n",
        "    X = torch.tensor([output[-1]],device=device)\n",
        "    Y = model(X, state)\n",
        "    if t < len(prefix) - 1:\n",
        "      output.appebd(char_to_idx[prefix[t + 1]])\n",
        "    else:\n",
        "      output.append(int(Y.argmax(axis=1).item()))\n",
        "    return ''.join([idx_to_char[i] for i in output])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0rmmNn-5Wg9"
      },
      "outputs": [],
      "source": [
        "def train(model, data, epochs, tbptt_step, pred_period, prefixes):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters())\n",
        "    # TODO one hot encode and gradient clip in here\n",
        "    for epoch in range(epochs):\n",
        "        l_sum, n, start = 0.0, 0, time.time()\n",
        "        for i, (x, y) in enumerate(data):\n",
        "            outputs = model(x)\n",
        "            loss = criterion(outputs, y)\n",
        "\n",
        "            if (i + 1) % tbptt_step == 0:\n",
        "                optimizer.zero_grad()\n",
        "                torch.mean(loss.backward())\n",
        "                optimizer.step()\n",
        "            l_sum += loss.item()\n",
        "            n += tbptt_step\n",
        "        if (epoch + 1) % pred_period == 0:\n",
        "          print('epoch %d, perplexity %f, time %.2f sec' %(\n",
        "              epoch + 1, math.exp(l_sum / n), time.time() - start))\n",
        "          for prefix in prefixes:\n",
        "            print(' -', predict_rnn())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZuQy_sqx-Sr7"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "num_epochs = 1\n",
        "net = RNN(vocab_size, 256, vocab_size)\n",
        "initialize_model(net)\n",
        "train(net, raw_dataset, num_epochs, batch_size)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "20c09cea5ede3d49818594c8c0a7d6d3389990e398eb6d0bd0aabf1d5d9d31cd"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
